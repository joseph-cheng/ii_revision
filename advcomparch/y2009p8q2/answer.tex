\input{../../template.tex}

\begin{document}
\begin{enumerate}[label=(\alph*)]
  \item
  The use of condition codes complicates the implementation of a superscalar processor with O3 execution because it introduces implicit dependencies between all instructions that generate condition codes, and all instructions that use condition codes (even if the condition codes generated by an instruction are not going to be used by that particular instruction!).

  This means that we effectively limit the amount of ILP that we can extract through traditional O3 execution because the number of dependencies is so high. We could amend this, however, by introducing additional hardware to our processor such that the correct condition codes are read by branches, and that the correct condition codes are set on committing instructions.

\item
  We want our branch predictor to be fast, ideally producing a result within one cycle. However, deep pipelines often have very short clock periods, making it hard to achieve both speed and accuracy for our branch predictor. Furthermore, we are limited by the usual constraints of area and power, since as the branch predictor grows more complex, it will use more space on the chip (that could be used for things like a more complex pipeline, more cores, more cache, etc.), and will consume more power, making the chip run hotter and thus likely having to sacrifice performance in other areas to stay within power budget.

\item
  The branch predictor predicts whether or not a branch will be taken. A branch target buffer predicts the target address of a taken branch. This target buffer is often filled by observing the target of a branch once it has been taken for the first time.

  So, if we suppose a branch has already been taken, and will be taken when it is next reached, and our predictor is able to predict this. One realistic case of this might be the branch at the end of a loop, which will be taken multiple times, and will almost always be taken (to go to the start of the loop).

  In this case, when we fetch the instruction, we will feed it to our branch predictor, which should predict that the branch is taken. When we feed the address of this branch to our branch target buffer, this should tell us the correct target address of the branch. Then, on the next cycle, since we predicted the branch was taken, we should fetch from the predicted target address given by the BTB.

\item
  \begin{enumerate}[label=(\roman*)]

    \item
      Loop unrolling improves performance because we now no longer have branches between a lot of iterations of the loop. This means that it is easier to exploit ILP because we no longer have a control dependency between each iteration, meaning that optimisations like reordering instructions between iterations is possible.

      Predicated execution helps improve performance of loops in the case that there is a branch within a loop, for example:

\begin{verbatim}
s = 0
for i in range(0,1000000):
  if i%2 == 0:
    s += a[i]
  else:
    s += a[i*2]
\end{verbatim}

It is likely that the overhead of a branch will be greater than the instructions that are executed within the branch, so by introducing predicated execution we can remove this overhead and improve loop performance.

\item
  Loop unrolling increases static code size, which means that it may not fit entirely in the instruction cache, drastically reducing performance, or may stop other programs from fitting entirely in the instruction cache.

  Predicated executions requires condition codes, whose disadvantages are described in (a). Depending on the exact loop, the overhead of a branch in a loop might actually not be that high (especially if it can be accurately predicted) compared to the contents of the branch, and so we may actually worsen performance.

     
      
  \end{enumerate}
        
\end{enumerate}
\end{document}
